# 实体分割 (Mask R-CNN)

## 1. 算法简介

Mask R-CNN算法是最常用的实体分割算法之一。ModelMaker平台提供了高效的Mask R-CNN算法实现。用户只需要准备好标记好的训练数据，即可由平台自动完成模型训练与部署。

## 2.训练数据准备

用户需要准备带标注的训练数据。训练数据必须具如下结构：

```
DATA_DIR
│
└───train
│   │   annotation.json
│   └───images
│       │   images1.jpg
│       │   images2.jpg
│       │   ...
│   
└───validate
│   │   annotation.json
│   └───images
│       │   images1.jpg
│       │   images2.jpg
│       │   ...
│   
```

训练数据所在文件夹中，包括 `train` 和 `validate` 两个文件夹，分别包含训练集数据与验证集数据。这两个文件夹下，分别存放一个images子文件夹（存放图像文件）以及一个annotation.json文件（记录标注信息）。其中，标注文件annotation.json为json格式，示例如下：

```python
[
  {
   "file_name": "1.jpg",  # images文件夹中图像文件的文件名
   "class": [1, 2, 3],    # 标注框中的实体类别，此图像中标注了3个实体
   "boxes": [[x1, y1, x2, y2], [x1, y1, x2, y2], [x1, y1, x2, y2],] # 3个实体对应的标注框。其中，(x1,y1)为标注框左上角的坐标，而(x2,y2)为标注框右下角的坐标
   "segmentation": [ [[x1,y1,x2,y2,x3,y3,...],[x1,y1,x2,y2,x3,y3,...]], # 实体1
                     [[x1,y1,x2,y2,x3,y3,...],[x1,y1,x2,y2,x3,y3,...]], # 实体2
                     [[x1,y1,x2,y2,x3,y3,...],[x1,y1,x2,y2,x3,y3,...]], # 实体3
                   ]
      # 分割标注，每个实体每一组多边形表示（一个实体可能需要多个多边形标注）。其中，每个多边形用一组坐标点表示，每个坐标点为多边形的一个顶点。
  }, 
  {
   "file_name": "2.jpg", 
   "class": [1, 3, 2], 
   "boxes": [[x1, y1, x2, y2], [x1, y1, x2, y2], [x1, y1, x2, y2],]
  }, 
]
```

## 3. 超参配置

- 用户可配置的超参如下：
  - step_per_epoch： 每个epoch所包含的迭代次数。1个epoch表示遍历过一遍训练集中的所有样本。默认值：20
  - eval_period：在验证集上检验准确率的周期。默认值为50，即每50个epoch计算一次在验证集上的准确率。
  - weight_decay: 正则项系数，控制正则项对损失函数的影响程度，以更好地防止过拟合。默认值：1*10<sup>-4</sup>
  - base_lr：基础学习率(learning rate)。默认值：2.0*10<sup>-3</sup>
  - lr_schedule：学习率调节策略。包含3个训练步数(step)，对应训练过程中三个阶段。每个阶段的学习率系数（基于基础学习率base_lr）为0.1,0.01,0.001。通常，在训练开始阶段使用相对较大的学习率值，而在训练后期使用较小的学习率值有利于模型收敛。默认值：[120000, 160000, 180000]
  - warmup: 目标检测模型较难训练，需要采取warmup策略。即在训练刚开始的若干次迭代中，先使用一个较小的学习率，而后再使用常用的学习率设置策略。此参数控制warmup（即使用较小的学习率）的迭代次数。默认值：500
  - warmup_init_lr：warmup阶段的初始学习率。此值一般需要设置为小于基础学习率base_lr。默认值：0.33*10<sup>-3</sup>

## 4. 模型训练

准备好训练数据并配置好超参数后，即可将数据上传到平台上进行模型训练。

## 5. 模型部署

模型训练完成后，模型部署可由平台自动完成。模型部署后用户可直接向平台发送推理请求并接收推理结果。

### 5.1 推理请求API

用户可以使用任意工具以Http POST方式向平台发送推理请求。简单的请求代码如下（不考虑鉴权）:

```python
import requests

files = {'image': ('1.jpg', open('./1.jpg', 'rb'), 'image/jpeg')}
r = requests.post(server_url, files=files)
```

### 5.2 推理结果

推理结果以http响应(reponse)形式返回，并使用json格式存储。具体字段如下示例：

```python
  {
   "labels": [1,2,3],  # 检测结果中各个标注框中的实体类别。
   "boxes": [[x1, y1, x2, y2], [x1, y1, x2, y2], [x1, y1, x2, y2]], # 检测结果标注框。每个标注框对应一个实体。
   "segmentation": [ [[x1,x2,x3,...],...], # 实体1掩模(mask)
                     [[x1,x2,x3,...],...], # 实体2掩模(mask)
                     [[x1,x2,x3,...],...], # 实体3掩模(mask)
                   ] # 分割结果
   "scores": [0.93, 0.80, 0.90] # 各检测结果的置信度
  }
```

推理结果中，实体掩模(mask)为28*28的矩阵。可以使用如下示例代码将其转换为与bounding box等大小的掩模，并将掩模结果二值化：

```python
import cv2
mask = (cv2.resize(mask, (w, h)) > 0.5).astype('uint8')
```

转换并二值化后的结果即为像素级别的分类结果，即语义分割结果。

